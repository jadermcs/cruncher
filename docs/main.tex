\documentclass{article}
\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage[T1]{fontenc}
\usepackage{syntax}
\usepackage{url}
\usepackage{fancyvrb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{pgf}
\usepackage{tikz}
\usetikzlibrary{arrows,automata}
\usetikzlibrary{positioning}
\DefineVerbatimEnvironment{code}{Verbatim}{fontsize=\small}
\DefineVerbatimEnvironment{example}{Verbatim}{fontsize=\small}
\newcommand{\ignore}[1]{}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\lstdefinestyle{mystyle}{
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    keepspaces=true,
    numbers=left,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
}
\lstset{style=mystyle}
\tikzset{
    state/.style={
           rectangle,
           rounded corners,
           draw=black, very thick,
           minimum height=2em,
           inner sep=2pt,
           text centered,
           },
}
\newenvironment{allintypewriter}{\ttfamily}{\par}

\title{Cruncher:\\
\large A Functional Language for Handling Files and Folders}
\author{Jáder M. C. de Sá \\
        Department of Computer Science\\
        University of Brasília, Brazil \\
        jader.martins@ipea.gov.br}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
\label{sec:intro}
The Unix Shell is a general denomination for a command line interpreter
(and a scripting language) that provides for users and systems admins an
interface to control the execution of operating system task's in Unix-like
environments \cite{negus2010linux}, this name comes from earlier times
when OS had this only interface covering the user interaction (like a shell
protecting the pearl). The Shell provides a way to create executable scripts,
execute programs, manage file-systems, compile code and other general computer
manipulation tasks \cite{negus2010linux,blum2008linux}.

Although Shell be a very old computer technology later being replaced by
graphical interfaces, many users (specially super-users) prefer this less
intuitive interface \cite{newham2005learning} for daily tasks. The \textit{sh}
is the precursor project and the default shell in many Unix distributions but
many other shells were also developed with similar behavior but distinct
orientation, to cite a few, the most popular ones are \textit{bash}
\cite{bash}, \textit{zsh} \cite{zsh} and \textit{fish} \cite{fish}.

Allied with the Shell, many external tools were developed to supply the needs
of Unix users \cite{negus2010linux} but those were not integrated natively in
any of those shell scripting language resulting in an inconsistent language for
files handling and operations. Tools like tar, sed, md5, etc, each has a
distinct parameter handling paradigm.

In modern \textbf{data processing}, a computing paradigm presented himself
as a suitable and intuitive way to describe massive computations and is
adopted by major frameworks like Hadoop, Spark and Kafka. The MapReduce
is a computational paradigm that decompose computations in a Maps and
Reduction operations, it has a clear and efficient model of computation
besides not being so trivial to describe any computation in this paradigm
\cite{afrati2012vision}.

This paper proposes a language designed for \textbf{data processing} in
shell, specifically files and folder processing in a standardized syntax,
it is resembles the \textit{bash} language but it adds a semantically
consistent operation for external tools with a intuitive syntax. It is
organized in the following manner, Section \ref{sec:formal} describes the
formal grammar for Cruncher language, \ref{sec:semantics} presents the
semantics of principal keywords in the language, and finally Section
\ref{sec:conclusion} concludes the paper.

\section{Formal Description}
\label{sec:formal}
In this section we present the formal grammar for the \textit{Cruncher}
language, also we discuss notation and specification of the grammar. The
language is extended the list comprehension, blobs and mappings, additionally,
it incorporates the main external tools from Unix shell in the same syntax. It
has the main grammatical structures presented in \textit{Haskell}, so we took
the bash reference \cite{marlow2010haskell} as basis for this grammar.

\paragraph{Notation Convention}
These notations convention are used for presenting syntax:

\begin{grammar}
\item $\epsilon$ - empty symbol.

\item ( \textit{pattern} )* - zero or more repetitions of the pattern.

\item \textit{symbol1} "..." \textit{symbol2} - a choice from symbol1 to symbol2.

\item <\textit{definition}> - definition for a statement.

\item "\textvisiblespace" - in some points the space is made visible to
    emphasize his existence.
\end{grammar}

\subsection{Lexical Syntax}

\begin{grammar}
<program> ::= (<lexeme>|<whitespace>)*

<lexeme> ::= <reservedid>|<varid>|<conid>|<literal>|<special>|<reservedop>

<literal> ::= <integer>|<float>|<char>|<string>

<special> ::= "("|")"|","|";"|"["|"]"|"`"|"{"|"}"

<whitespace> ::= <whitestuff><whitestuff>*

<whitestuff> ::= <whitechar>|<comment>

<whitechar> ::= <newline>|"\\t"|"\textvisiblespace"

<newline> ::= "\\n"

<any> ::= anything except <newline>

<comment> ::= "-""-"<any><newline>

<digit> ::= "0"..."1"

<integer> ::= [+|-]<digit><digit>*

<float> ::= <integer>"."<digit>*[<expon>]

<expon> ::= ("e"|"E")[+|-]<integer>

<lsmall> ::= "a"..."z"|"_"

<lsmall> ::= "A"..."Z"

<symbol> ::= "!"|"#"|"\$"|"\%"|"&"|"*"|"+"|"."|"\\"|"/"|"<"|"="|">"|"?"|"@"|"|"|"^"|"-"|"~"|":"

<graphic> ::= <lsmall>|<llarge>|<symbol>

<char> ::= "'"<graphic>"'"

<string> ::= "\""<graphic>*"\""

<path> ::= ("_"|".")(<llarge>|<lsmall>|"."|"/")*

<reservedid> ::= "case"|"class"|"data"|"default"|"deriving"|"do"|"else"
\alt"foreign"|"if"|"import"|"in"|"infix"|"infixl"|"infixr"|"instance"
\alt"let"|"module"|"newtype"|"of"|"then"|"type"|"where"|"like"

<varid> ::= <lsmall>(<lsmall>|<llarge>|<digit>)*

<conid> ::= <llarge>(<lsmall>|<llarge>|<digit>)*

<reservedop> ::= ".."|":"|"::"|"="|"\\"|"|"|"<-"|"->"|"@"|"~"|"=>"
\end{grammar}

\subsection{Changes and Updates}
In the first version, the lexical syntax presented erros as advanced structures
were recognized at this step, but those more complex structures should be
recognized in the parser phase by a free context grammar. Also, the language
was missing some important token patterns, so all those were added to this
version.

\section{Semantics}
\label{sec:semantics}
The language main feature is inspired in the MapReduce paradigm, which is a
popular design for data processing frameworks, so this language uses Haskell as
his basis semantic. To facilitate the implementation many of the types will not
be implemented, only a subset of those (to have the basics functionality) will
be implemented. In this section we discuss the semantics and exemplify the
usage:

First we begin exemplifying the <crunch> keyword:

\begin{code}
-- replaces every occurrence of cat word in the files inplace.
main = do $
    $!("s/cat/dog/g") "/home/jader/files/*.txt" .


-- moves every content from those .txt files to a single .json file in json folder.
main = do $
    $> "/home/jader/files/*.txt" _"/home/jader/json/file.json"
\end{code}

It has an input folder or file and an output folder or file, depending on the
kind of operation.  In Table \ref{tab:operations} some extra references for
additional symbols are shown, every operation has a single symbol. It replaces
the following Unix shell commands: \texttt{mv}, \texttt{rename}, \texttt{sed},
\texttt{tar} and \texttt{shaXsum}.

The list comprehension applies implicit operations on string in the same sense
in \ref{tab:maps} the mappings which has 2 symbols are shown. They occur in
list comprehension to iterate in files, here is an example of his usage:

\begin{code}
-- creates a backup for every .txt file in the folder.
main = do $
    $& "/home/jader/files/*" [++ ".backup" \ "/home/jader/files/*" if endsWith ".txt"]
\end{code}

The type of operation alternates the kind of matching between files, some have
a direct mapping, some perform an aggregation, and others both. For in-place
mapping the output files can be implicitly defined by ``.'' if aggregation is
we must specify the  ``\_'' to be performed.

\begin{table}[ht]
\centering
\caption{Operations description}
\label{tab:operations}
\begin{tabular}{|c|c|l|}
\hline
Operation   & Symbol & Description\\ \hline
Move        & >      & Move given files or directories \\
Rename      & \&     & Renames given files or directories \\
Edit        & !      & Stream editor operations \\
Compression & @      & Compress files and/or directories using tar \\
Hash        & *     & Calculates the hash \\
\hline
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{Maps description}
\label{tab:maps}
\begin{tabular}{|r|c|l|}
\hline
Mapping   & Symbol & Description\\ \hline
Identity  & ..     & Return same given value \\
Filter    & ff     & Filter a given pattern \\
Replace   & rr     & Replace a given pattern \\
Cut       & cc     & Remove a substring \\
Concat    & ++     & Concatenate strings \\
\hline
\end{tabular}
\end{table}

\section{Error Handling}
For the scanner phase, only local structures are recognized, so we use counters,
for line and column, to track locations of points with unrecognized tokens,
i.e., \texttt{line_count} and \texttt{line_count}, respectively. In the
code bellow is exemplified this operation.

\begin{lstlisting}[language=C, caption=Example of code monitoring lines and columns.]
    %{
    int line_count = 1;
    int col_count = 1;
    %}
    EOL     \n
    ... /*some patterns*/
    %%
    EOL {
        line_count++;
        col_count = 1;
    }

    ... /*some patterns*/

    . {
        printf("Pattern unrecognized at line %d, column %d: %s\n",
                line_count, col_count+yyleng, yytext);
        return 1;
    }
\end{lstlisting}

If any other pattern is unrecognized it is captured by the `.', and reported
latter.

\section{Procedures}
The Flex scanner provides many directives and variables to help in the scanning
process, four directives of this tool was used, \texttt{yyleng},
\texttt{yytext}, \texttt{yyin} and \texttt{yylineno}. The \texttt{yyleng}
returns the length of the current string recognized, the \texttt{yytext}
returns this string, the \texttt{yyin} read and return the file to be scanned.
All tokens are recognized and categorized by a macro \texttt{printLexeme}
defined in the following manner:

\begin{verbatim}
#define printLexeme(type) printf("A %s: \"%s\" at line %d\n",\
                                (type), yytext, line_count);
\end{verbatim}

When an error occur in the scanning phase, the scanner saves those informations
in a struct and continues the scanning process. At the end those errors are
reported. Here is an example:

\begin{verbatim}
typedef struct {
     char error_type[64][16];
     char error_msg[64][128];
     int error_count;
     int at_line[64];
     int at_column[64];
} lexErrors;
\end{verbatim}

\section{Symbol Table}
As Haskell is a functional language it doesn't have variables, only functions,
so the symbol table only take care of function types. The function types in
Haskell could be explicit or implicit but for easiness of implementation in
Cruncher it should be explicit, with this types declared, every function will
be presented in the symbol table with type, id, location, and a pointer to a
local symbol table. In Figure \ref{fig:symboltable} is shown an example of
references in symbol table, initially a global table is created and for each
function a local table is defined with local definitions.

\begin{figure}[ht]
\label{fig:symboltable}
\centering
\begin{tikzpicture}[->,>=stealth']

 \node[state] (t0)
 {\begin{tabular}{l}
  \textbf{Global Table}\\
  \begin{allintypewriter}
  \begin{tabular}{ccc}
          type & id & local_table\\\hline
          Int   & func1 & *1\\
          String& func2 & NULL\\
          Float & func3 & *3\\
          Int   & func4 & NULL
           \end{tabular}
 \end{tabular}
  \end{allintypewriter}
 };

 \node[state,
  yshift=2cm,
  right of=t0,
  node distance=6.5cm,
  anchor=center] (t1)
 {\begin{tabular}{l}
  \textbf{Local Table 1}\\
  \begin{allintypewriter}
  \begin{tabular}{ccc}
          type & id & local_table\\\hline
          Int   & funcl1 & NULL\\
          Int   & funcl2 & *2
           \end{tabular}
 \end{tabular}
  \end{allintypewriter}
 };

 \node[state,
  below of=t1,
  node distance=3.0cm,
  anchor=center] (t2)
 {\begin{tabular}{l}
  \textbf{Local Table 2}\\
  \begin{allintypewriter}
  \begin{tabular}{ccc}
          type & id & local_table\\\hline
          Int   & funcl1 & NULL
           \end{tabular}
 \end{tabular}
  \end{allintypewriter}
 };

 \node[state,
  yshift=1cm, 		% move 2cm in y
  below of=t2,
  node distance=3.0cm, 	% distance to QUERY
  anchor=center] (t3)
 {\begin{tabular}{l}
  \textbf{Local Table 3}\\
  \begin{allintypewriter}
  \begin{tabular}{ccc}
          type & id & local_table\\\hline
          Int   & funcl1 & NULL\\
          Float & funcl2 & NULL
           \end{tabular}
 \end{tabular}
  \end{allintypewriter}
 };

 \path (t0) 	edge[bend left=20]  node[anchor=south,above]{*1} (t1)
 (t1)     	edge[bend right=20] node[anchor=south,right]{*2} (t2)
 (t0)     	edge[bend right=20] node[anchor=south,below]{*3} (t3);

\end{tikzpicture}
\caption{Example of symbol table.}
\end {figure}

\section{Test files}
There are two files for valid code examples and two for invalid codes, the
valid ones have the \texttt{test-valid} prefix, and the invalid,
\texttt{test-invalid} prefix.


\section{Conclusion}
\label{sec:conclusion}
The language presented in this paper aims to achieve a clear and consistent
syntax for files and folders handling, replacing the usual shell scripting that
requires external tools to made common operations that should be native in the
language. It is done by applying the functional scheme from Haskell allied to
the MapReduce paradigm. With two additional structures, it captures major
operations done in the Unix terminal using a minimal and intuitive syntax.

\bibliographystyle{alpha}
\bibliography{ref.bib}

\end{document}
